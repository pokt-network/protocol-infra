# This is the snapshot service for the protocol-nj cluster.
# Components:
# Nginx server that exposes endpoints for uploading and downloading snapshots.
# PVC for storing uploaded/distributed files.
# CronJob to trigger creation and deletion of snapshots.
# CronJob process:
# - Stops full node;
# - Creates a `poktrolld snapshot` (pruned snapshot);
# - Archives full data directory (archival snapshot);
# - Uploads snapshots to snapshot service;
# - Performs an atomic swap/rename of the snapshots so the `latest` link points to the new snapshot;
# - Starts the full node back up;

# 1) PVC for storing uploaded/distributed files.
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: snapshot-data-pvc
#   namespace: protocol-common
# spec:
#   accessModes:
#     - ReadWriteOnce
#   resources:
#     requests:
#       storage: 100Gi
#   storageClassName: "vultr-block-storage-hdd" # Use HDD storage for lower cost

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: snapshot-data-ssd
  namespace: protocol-common
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
  storageClassName: "vultr-block-storage"
---
# 2) ConfigMap with OpenResty config, including DAV for one server block
#    and read-only for another.
apiVersion: v1
kind: ConfigMap
metadata:
  name: openresty-config
  namespace: protocol-common
data:
  nginx.conf: |
    # Main Nginx (OpenResty) configuration
    worker_processes auto;  # Auto-detect number of cores

    # Increase file descriptors limit
    worker_rlimit_nofile 65535;

    events {
      worker_connections 16384;  # Increased for high concurrency
      multi_accept on;           # Accept as many connections as possible
    }

    http {
      # File handling optimizations for large files
      open_file_cache max=10000 inactive=5m;
      open_file_cache_valid 2m;
      open_file_cache_min_uses 1;
      open_file_cache_errors on;
      
      # Buffer size optimizations
      client_body_buffer_size 128k;
      client_max_body_size 0;    # No limit on body size
      
      # ------------------------------------------------------
      # SERVER #1: WebDAV on port 8080 (for PUT, MOVE, DELETE)
      # ------------------------------------------------------
      server {
        listen       8080;
        # can add a server_name later if necessary:  webdav.example.com;

        # The main document root (mounted from PVC to /data):
        root /data/snapshots;

        # Use the same /data for temporary upload path to keep it on same filesystem.
        client_body_temp_path /data/tmp;

        # Enable DAV methods
        dav_methods PUT DELETE MKCOL COPY MOVE;
        create_full_put_path on;
        dav_access  user:rw group:rw all:r;

        # If we want to restrict write methods:
        # limit_except GET HEAD {
        #   allow 10.0.0.0/8;  # example
        #   deny  all;
        # }

        # Allow for large files
        client_max_body_size 0;
      }

      # -----------------------------------------------------
      # SERVER #2: Distribution server on port 8081 (read-only)
      # -----------------------------------------------------
      server {
        listen       8081;
        # can add a server_name later if necessary:  distro.example.com;

        root /data/snapshots;
        
        # Optimize for torrent web seeding
        location / {
          autoindex on;
          
          # Enable byte-range requests (required for torrent web seeding)
          add_header Accept-Ranges bytes;
          
          # Set appropriate cache headers for large files
          expires 30d;
          add_header Cache-Control "public, no-transform";
        }
      }
    }

---
# 3) Deployment: runs OpenResty with the above config, mounting the PVC
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openresty-webdav-snapshot
  namespace: protocol-common
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openresty-webdav-snapshot
  template:
    metadata:
      labels:
        app: openresty-webdav-snapshot
    spec:
      containers:
        - name: openresty
          # Example OpenResty image that typically includes the WebDAV module;
          # verify or use a custom build if needed.
          image: "openresty/openresty:1.27.1.1-1-buster-fat"
          ports:
            - containerPort: 8080
            - containerPort: 8081
          volumeMounts:
            - name: config-volume
              mountPath: /usr/local/openresty/nginx/conf/nginx.conf
              subPath: nginx.conf
            - name: data
              mountPath: /data
      volumes:
        - name: config-volume
          configMap:
            name: openresty-config
            items:
              - key: nginx.conf
                path: nginx.conf
        - name: data
          persistentVolumeClaim:
            claimName: snapshot-data-ssd

---
# 4) Services: one for the WebDAV port, one for the distro port
apiVersion: v1
kind: Service
metadata:
  # Not meant to be used by the public internet, but for internal use by the
  # service to upload snapshots.
  name: snapshot-service-webdav
  namespace: protocol-common
spec:
  selector:
    app: openresty-webdav-snapshot
  ports:
    - name: http-webdav
      port: 80
      targetPort: 8080
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  name: snapshot-service-internet-direct
  namespace: protocol-common
  annotations:
    service.beta.kubernetes.io/vultr-loadbalancer-ssl: poktroll-wildcard-tls
    service.beta.kubernetes.io/vultr-loadbalancer-protocol: "https"
    service.beta.kubernetes.io/vultr-loadbalancer-backend-protocol: "http"
    service.beta.kubernetes.io/vultr-loadbalancer-https-ports: "443"
    service.beta.kubernetes.io/vultr-loadbalancer-ssl-pass-through: "false"
spec:
  selector:
    app: openresty-webdav-snapshot
  ports:
    - name: http-distro
      port: 80
      targetPort: 8081
  type: LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: snapshot-service-internet
  namespace: protocol-common
spec:
  selector:
    app: openresty-webdav-snapshot
  ports:
    - name: http-distro
      port: 80
      targetPort: 8081
  type: ClusterIP
---
# 5) Ingress for the snapshot service (snapshots.us-nj.poktroll.com)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: snapshot-service-ingress
  namespace: protocol-common
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  ingressClassName: nginx
  rules:
    - host: snapshots.us-nj.poktroll.com
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: snapshot-service-internet
                port:
                  number: 8081
  tls:
    - secretName: poktroll-wildcard-tls
      hosts:
        - snapshots.us-nj.poktroll.com

